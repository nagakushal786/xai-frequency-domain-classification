{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4b8af4",
   "metadata": {},
   "source": [
    "## Hierarchial Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62205d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "credit_score=pd.read_csv(\"data/credit_score.csv\")\n",
    "\n",
    "# Select features\n",
    "df_features=credit_score.drop(['CUST_ID', 'CAT_GAMBLING', 'CAT_DEBT', \n",
    "                               'CAT_CREDIT_CARD', 'CAT_MORTGAGE',\n",
    "                               'CAT_SAVINGS_ACCOUNT', 'CAT_DEPENDENTS',\n",
    "                               'CREDIT_SCORE', 'DEFAULT'], axis=1)\n",
    "\n",
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "df_scaled=scaler.fit_transform(df_features)\n",
    "df_scaled=pd.DataFrame(df_scaled, columns=df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6215583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose so that each row is a feature\n",
    "df_transposed=df_scaled.transpose()\n",
    "print(np.shape(df_transposed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hierarchial clustering on features\n",
    "linked=linkage(df_transposed, method='ward', metric='euclidean')\n",
    "print(np.shape(linked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linked=pd.DataFrame(linked,\n",
    "                       columns=['c1', 'c2', 'distance', 'size'])\n",
    "df_linked[['c1', 'c2', 'size']]=df_linked[['c1', 'c2', 'size']].astype('int')\n",
    "\n",
    "df_linked.head(10)\n",
    "\n",
    "# c1, c2 - indices of 2 clusters included in the new cluster\n",
    "# distance - distance between the 2 clusters\n",
    "# size - number of features in the resulting cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c55c25",
   "metadata": {},
   "source": [
    "### Visualizing the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df87232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dendrogram to visualize the feature clustering\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "dendrogram(\n",
    "    linked,\n",
    "    # Root cluster at top, individual features at bottom\n",
    "    orientation='top',\n",
    "    labels=df_transposed.index,\n",
    "    distance_sort='descending',\n",
    "    show_leaf_counts=True\n",
    ")\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Ward distances')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340786e",
   "metadata": {},
   "source": [
    "### Group features into clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e6f71",
   "metadata": {},
   "source": [
    "* `fcluster` (from `scipy.cluster.hierarchy`) converts a **hierarchical clustering** (the dendrogram encoded by `linked`) into **flat cluster labels** for each original sample.\n",
    "\n",
    "* `linked` should be the **linkage matrix** you got from `linkage(X, method=...)`. It’s an `(n-1) x 4` array describing the sequence of merges: which clusters merged, at what distance, and the size of the new cluster.\n",
    "\n",
    "* `criterion='maxclust'` tells `fcluster` to **cut the dendrogram** so that the number of resulting clusters is **no more than** `t`. In practice this yields **exactly `t` clusters** unless there are ties/degeneracies.\n",
    "\n",
    "* `t=num_clusters` sets that `t` to 10, so you get (typically) **10 clusters**.\n",
    "\n",
    "* The return value `labels` is a 1D integer array of length `n_samples`, with values like `1, 2, ..., k` indicating which cluster each sample belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters=10\n",
    "\n",
    "labels=fcluster(linked, t=num_clusters, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9610340",
   "metadata": {},
   "source": [
    "#### 1. What `.corr()` does\n",
    "\n",
    "* `pandas.Series.corr()` computes the **Pearson correlation coefficient** between two Series (columns) by default.\n",
    "* Formula:\n",
    "\n",
    "$$\n",
    "r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\, \\sigma_Y}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\text{Cov}(X, Y)$ = covariance between features `X` and `Y`\n",
    "* $\\sigma_X, \\sigma_Y$ = standard deviations of `X` and `Y`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Step-by-step calculation\n",
    "\n",
    "Suppose we’re correlating `CREDIT_SCORE` (Y) with some feature column (X):\n",
    "\n",
    "1. **Mean-center both variables**\n",
    "\n",
    "   $$\n",
    "   X' = X - \\bar{X}, \\quad Y' = Y - \\bar{Y}\n",
    "   $$\n",
    "\n",
    "2. **Compute covariance**\n",
    "\n",
    "   $$\n",
    "   \\text{Cov}(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n X'_i \\, Y'_i\n",
    "   $$\n",
    "\n",
    "3. **Normalize by variances**\n",
    "\n",
    "   $$\n",
    "   r = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\frac{1}{n-1}\\sum (X'_i)^2} \\; \\sqrt{\\frac{1}{n-1}\\sum (Y'_i)^2}}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba631b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation between features and credit score\n",
    "correlations=[]\n",
    "\n",
    "for col in df_features.columns:\n",
    "    corr=credit_score[\"CREDIT_SCORE\"].corr(credit_score[col])\n",
    "    corr=round(corr, 3)\n",
    "    correlations.append(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c89dd5",
   "metadata": {},
   "source": [
    "* `df_features.columns` → an Index of feature names.\n",
    "* `labels` → the cluster label for each feature (from your clustering step).\n",
    "* `correlations` → Pearson r between each feature and CREDIT\\_SCORE.\n",
    "* `zip(...)` pairs items position-wise, e.g. `(feature_i, label_i, corr_i)`.\n",
    "* `list(...)` materializes that iterator into a list of tuples for DataFrame construction.\n",
    "* `pd.DataFrame(..., columns=...)` builds a DataFrame with explicit column names:\n",
    "\n",
    "  * **feature**: column name from `df_features`\n",
    "  * **cluster**: integer cluster id (1..k)\n",
    "  * **correlation**: signed Pearson correlation with the target\n",
    "\n",
    "```python\n",
    "df_clusters['abs_corr'] = df_clusters['correlation'].abs()\n",
    "```\n",
    "\n",
    "* Creates a new column **abs\\_corr** as the absolute value of the signed correlation.\n",
    "* Purpose: rank features by **strength** of association regardless of sign.\n",
    "\n",
    "```python\n",
    "df_clusters.sort_values(by=['cluster', 'abs_corr'], ascending=[True, False], inplace=True)\n",
    "```\n",
    "\n",
    "* Sorts rows by two keys:\n",
    "\n",
    "  1. **cluster** ascending → groups features cluster-by-cluster.\n",
    "  2. **abs\\_corr** descending → within each cluster, strongest correlations first.\n",
    "* `inplace=True` mutates `df_clusters` instead of returning a new DataFrame.\n",
    "\n",
    "```python\n",
    "df_clusters.reset_index(drop=True, inplace=True)\n",
    "```\n",
    "\n",
    "* After sorting, the old row order (index) is meaningless; this resets to `0..n-1`.\n",
    "\n",
    "* `drop=True` discards the old index rather than moving it into a column.\n",
    "\n",
    "* `inplace=True` modifies the DataFrame directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44474ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters=pd.DataFrame(\n",
    "    list(zip(df_features.columns, labels, correlations)),\n",
    "    columns=['feature', 'cluster', 'correlation']\n",
    ")\n",
    "\n",
    "df_clusters['abs_corr']=df_clusters['correlation'].abs()\n",
    "\n",
    "df_clusters.sort_values(by=['cluster', 'abs_corr'], ascending=[True, False], inplace=True)\n",
    "df_clusters.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_clusters.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5afc86",
   "metadata": {},
   "source": [
    "### Sense check the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_features=df_clusters[df_clusters['cluster']==2]['feature'].tolist()\n",
    "c3_features=df_clusters[df_clusters['cluster']==3]['feature'].tolist()\n",
    "\n",
    "print(c2_features)\n",
    "print(c3_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fa7c1",
   "metadata": {},
   "source": [
    "```python\n",
    "corr = credit_score[c2_features].corr()\n",
    "```\n",
    "\n",
    "* `c2_features` → should be a list of column names belonging to cluster 2 (from your earlier clustering).\n",
    "* `credit_score[c2_features]` → selects those columns from the DataFrame.\n",
    "* `.corr()` → computes the **pairwise Pearson correlation matrix** among the selected features:\n",
    "\n",
    "  * Result is a square DataFrame (size = number of features in cluster 2 × same).\n",
    "  * Values range between **-1 and +1**.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(5, 4))\n",
    "```\n",
    "\n",
    "* Creates a new matplotlib figure with width=5 inches, height=4 inches.\n",
    "* Controls the plot’s overall size.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5,\n",
    "    fmt='.1f',\n",
    "    annot_kws={\"size\": 7},\n",
    "    vmin=-1,\n",
    "    vmax=1\n",
    ")\n",
    "```\n",
    "\n",
    "This draws the heatmap using **seaborn**:\n",
    "\n",
    "* **`corr`** → the correlation matrix is the input (a 2D numeric table).\n",
    "\n",
    "* **`annot=True`** → show the actual correlation values inside each cell.\n",
    "\n",
    "* **`cmap='coolwarm'`** → color map: blue for negative values, red for positive values, white near zero.\n",
    "\n",
    "* **`linewidths=0.5`** → thin white gridlines between cells.\n",
    "\n",
    "* **`fmt='.1f'`** → format annotations with 1 decimal place.\n",
    "\n",
    "* **`annot_kws={\"size\": 7}`** → annotation font size.\n",
    "\n",
    "* **`vmin=-1, vmax=1`** → fixes the color scale so -1 = full blue, 0 = white, +1 = full red.\n",
    "  Ensures all heatmaps are comparable.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "plt.title(\"Cluster 2\")\n",
    "```\n",
    "\n",
    "* Adds a title above the heatmap.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "plt.xticks(size=7)\n",
    "plt.yticks(size=7)\n",
    "```\n",
    "\n",
    "* Reduces the tick-label font size on the x and y axes to 7, keeping labels readable in small plots.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations for features in cluster 2\n",
    "corr=credit_score[c2_features].corr()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5,\n",
    "    fmt='.1f',\n",
    "    annot_kws={\"size\": 7},\n",
    "    vmin=-1,\n",
    "    vmax=1\n",
    ")\n",
    "\n",
    "plt.title(\"Cluster 2\")\n",
    "plt.xticks(size=7)\n",
    "plt.yticks(size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations for features in cluster 3\n",
    "corr=credit_score[c3_features].corr()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5,\n",
    "    fmt='.1f',\n",
    "    annot_kws={\"size\": 7},\n",
    "    vmin=-1,\n",
    "    vmax=1\n",
    ")\n",
    "\n",
    "plt.title(\"Cluster 3\")\n",
    "plt.xticks(size=7)\n",
    "plt.yticks(size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532d0aa",
   "metadata": {},
   "source": [
    "```python\n",
    "cbar = plt.gcf().axes[-1]\n",
    "```\n",
    "\n",
    "* `plt.gcf()` — “get current figure”. It returns the `Figure` object that matplotlib is currently working with.\n",
    "\n",
    "* `.axes` — a list of all `Axes` objects in that `Figure` (main plot axes, maybe subplots, and any colorbar axes).\n",
    "\n",
    "* `[-1]` — picks the **last** `Axes` in that list.\n",
    "\n",
    "* **Typical effect:** after drawing a seaborn heatmap, matplotlib usually appends the colorbar as the last axes in the figure, so `plt.gcf().axes[-1]` commonly returns the **colorbar's Axes**. `cbar` then holds that Axes object.\n",
    "\n",
    "* **Caveat:** this assumes the colorbar is indeed the last axes. If you have multiple subplots or other axes, the last axes might not be the colorbar.\n",
    "\n",
    "```python\n",
    "cbar.tick_params(labelsize=7)\n",
    "```\n",
    "\n",
    "* `tick_params()` is an `Axes` method that controls tick/label appearance for that axes.\n",
    "\n",
    "* `labelsize=7` sets the **font size (in points)** of the tick labels on that axes — here, the colorbar ticks.\n",
    "\n",
    "* You can pass many other options to `tick_params()` (e.g., `rotation`, `length`, `width`, `direction='in'`), and you can target axes (`axis='x'/'y'`), but for a vertical colorbar `labelsize` is the usual parameter to shrink the numeric labels.\n",
    "\n",
    "```python\n",
    "plt.xticks(size=7)\n",
    "plt.yticks(size=7)\n",
    "```\n",
    "\n",
    "* These are convenience `matplotlib.pyplot` functions that set the **font size** of the tick labels on the **current axes** (the axes that matplotlib considers active).\n",
    "\n",
    "* `plt.xticks(size=7)` sets the x-axis tick label font size to 7 points. Same for `plt.yticks(size=7)` on the y-axis.\n",
    "\n",
    "* **Important:** `plt.xticks()` and `plt.yticks()` affect whichever axes is current — if you want to be explicit and safe, it’s better to use the axes object directly (`ax.tick_params(axis='x', labelsize=7)` / `ax.tick_params(axis='y', labelsize=7)`) so you don’t accidentally change the wrong axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations for features of cluster 2 and 3\n",
    "corr=df_features[np.append(c2_features, c3_features)].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5,\n",
    "    fmt='.1f',\n",
    "    annot_kws={\"size\": 7},\n",
    "    vmin=-1,\n",
    "    vmax=1\n",
    ")\n",
    "\n",
    "plt.title(\"Cluster 2 and 3\")\n",
    "plt.xticks(size=7)\n",
    "plt.yticks(size=7)\n",
    "\n",
    "# Change size of colorbar labels\n",
    "cbar=plt.gcf().axes[-1]\n",
    "cbar.tick_params(labelsize=7)\n",
    "plt.xticks(size=7)\n",
    "plt.yticks(size=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
